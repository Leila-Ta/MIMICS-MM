# MIMICS-MM
This study is the first attempt to explore the impact of clarification question modality on user preference in search engines. We introduce the multi-modal search clarification dataset, MIMICS-MM, containing clarification questions with associated expert-collected and model-generated images. We analyse user preferences over different clarification modes of text, image, and combination of both through crowdsourcing by taking into account image and text quality, clarity, and relevance. Our findings demonstrate that users generally prefer multi-modal clarification over uni-modal approaches. We explore the use of automated image generation techniques and compare the quality, relevance, and user preference of model-generated images with human-collected ones. The study reveals that text-to-image generation models, such as Stable Diffusion, can effectively generate multi-modal clarification questions. By investigating multi-modal clarification, this research establishes a foundation for future advancements in search systems.
MIMICS-MM contains 3 folders. The first folder includes the Phyton codes related to Dall.E and Stable diffusion models to generate images from the texts. The second folder includes crowdsourcing data and human annotations and the third folder contains the human-collected and computer-generated images. 

## Citation
If you found MIMICS-Duo useful, you can cite the following article:
```
Tavakoli, L., Castiglia, G., Calo, F., Deldjoo, Y., Zamani, H., & Trippas, J. R. (2024). Understanding Modality Preferences in Search Clarification. arXiv preprint arXiv:2406.19546.
```

bibtex:
```
@article{tavakoli2024understanding,
  title={Understanding Modality Preferences in Search Clarification},
  author={Tavakoli, Leila and Castiglia, Giovanni and Calo, Federica and Deldjoo, Yashar and Zamani, Hamed and Trippas, Johanne R},
  journal={arXiv preprint arXiv:2406.19546},
  year={2024}
}
```
